{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":11366903,"sourceType":"datasetVersion","datasetId":7114950},{"sourceId":11368035,"sourceType":"datasetVersion","datasetId":7114169}],"dockerImageVersionId":31012,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"source":"<a href=\"https://www.kaggle.com/code/alexoliveira0103/genai-capstone-project-the-ai-recipe-generator?scriptVersionId=233313931\" target=\"_blank\"><img align=\"left\" alt=\"Kaggle\" title=\"Open in Kaggle\" src=\"https://kaggle.com/static/images/open-in-kaggle.svg\"></a>","metadata":{},"cell_type":"markdown"},{"cell_type":"markdown","source":"# GenAI Capstone Project: The AI Recipe Generator üì∏üç≥\n\n**Team:** Alex Oliveira\n\n## 1. Introduction\n\n### 1.1. Overview\nWelcome to the AI Recipe Generator! This project have been developed as part of the Gen AI Intensive Course Capstone Challenge. \nIt‚Äôs a solution to a question we‚Äôve all asked: \"What can I make with what I‚Äôve got?\"\nNow, thanks to Generative AI, we have a compelling answer, for specific moments in life. \n\n### 1.2. The Problem: \"What Can I Make With This?\" ü§î\nYou open the fridge. A couple of eggs, a half-used bell pepper, maybe some forgotten herbs in the back. The question hits: What can I make with this?\nThis everyday uncertainty doesn‚Äôt just waste time‚Äîit contributes to a much bigger issue: food waste. Globally, we throw away billions of dollars worth of unused food every year. Often, it‚Äôs because we simply don‚Äôt know how to turn what we have into something we want to eat.\n\n### 1.3. The Solution: An AI-Powered Recipe Assistant üí°\nImagine snapping a photo of what‚Äôs in your fridge‚Äîand instantly receiving a recipe that uses exactly those ingredients. That‚Äôs what this AI-powered assistant does.\nBy combining image recognition, retrieval-augmented generation, and structured output, this tool creates a structured, easy-to-follow recipe, turning fragmented groceries into inspired, practical meals.\nIt‚Äôs not just about convenience, it‚Äôs about rethinking how we engage with food, and using technology to do it smarter.\n\n### 1.4. Gen AI Capabilities Showcase ‚ú®\nThis project demonstrates the application of the following capabilities learned during the course:\n\n1.  **Image Understanding:** Using the `gemini-pro-vision` model to analyze an uploaded image and accurately identify the food ingredients present.\n2.  **Retrieval Augmented Generation (RAG):**\n    * **Embeddings:** Generating numerical representations (`models/embedding-001`) of both the identified ingredients (query) and a database of existing recipes (documents).\n    * **Vector Search:** Using cosine similarity to find recipes in the database whose embeddings are closest to the query embedding, retrieving relevant cooking context.\n3.  **Structured Output (JSON Generation):** Instructing the `gemini-pro` model to generate the final recipe in a specific, predictable JSON format, making it easy to parse and display the recipe components (title, description, ingredients, instructions, times).\n\nLet's dive into the implementation!","metadata":{}},{"cell_type":"markdown","source":"## 2. Setup\n\n### 2.1. Install Libraries\nFirst, we install the necessary Python libraries. We need `google-generativeai` to interact with the Gemini API, `Pillow` for image handling, `pandas` for data manipulation (recipes), `numpy` for numerical operations (embeddings), and `scikit-learn` for similarity calculations.","metadata":{}},{"cell_type":"code","source":"# Ensure libraries are installed (run this cell once)\n!pip install google.generativeai pillow pandas numpy scikit-learn --quiet\nprint(\"Libraries potentially installed/updated.\")","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-04-11T15:17:14.372839Z","iopub.execute_input":"2025-04-11T15:17:14.373618Z","iopub.status.idle":"2025-04-11T15:17:19.223679Z","shell.execute_reply.started":"2025-04-11T15:17:14.37359Z","shell.execute_reply":"2025-04-11T15:17:19.222565Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### 2.2. Import Libraries & Configure API Key\nNext, we import the libraries and configure the Gemini API key.\n\n**IMPORTANT:** If you are running it in Kaggle, you need to add your Google AI API Key to the Kaggle Secrets tab.\n1.  Click on \"Add-ons\" in the right sidebar.\n2.  Go to \"Secrets\".\n3.  Add a new secret with the name `GOOGLE_API_KEY` and paste your API key as the value.","metadata":{}},{"cell_type":"code","source":"# --- Imports ---\nimport google.generativeai as genai\nfrom PIL import Image\nimport pandas as pd\nimport numpy as np\nfrom sklearn.metrics.pairwise import cosine_similarity\nimport json\nimport os\nimport io # Required for sending image data if needed, PIL object often works directly\nimport textwrap # For printing text nicely\nfrom IPython.display import display, Markdown, Image as IPImage # For better display in notebooks\n\n# --- Configuration & API Key ---\ntry:\n    from kaggle_secrets import UserSecretsClient\n    user_secrets = UserSecretsClient()\n    GOOGLE_API_KEY = user_secrets.get_secret(\"GOOGLE_API_KEY\")\n    genai.configure(api_key=GOOGLE_API_KEY)\n    print(\"‚úÖ Google AI API Key loaded successfully from Kaggle Secrets.\")\n    API_KEY_LOADED = True\nexcept Exception as e:\n    GOOGLE_API_KEY = None\n    API_KEY_LOADED = False\n    print(f\"‚ùå Could not load API key from Kaggle Secrets: {e}\")\n    print(\"‚û°Ô∏è Please add your GOOGLE_API_KEY to the 'Secrets' tab in your Kaggle notebook settings.\")\n    print(\"üö´ Notebook execution will be limited without the API Key.\")\n\n# --- Global Variables & Constants ---\n# !!! IMPORTANT: UPDATE these paths to point to your data in Kaggle Datasets !!!\n# Example: /kaggle/input/your-dataset-name/your-image.jpg\nIMAGE_PATH = '/kaggle/input/recipes-agent/images.jpg'\nRECIPE_CSV_PATH = '/kaggle/input/recipesmockdata-list/mock_detailed_cooking_recipes.csv' # Needs columns: title, ingredients_list, instructions\n\n# Embedding model - check availability for your API key region\n# Common options: 'models/embedding-001', 'models/text-embedding-004'\nEMBEDDING_MODEL_NAME = 'models/text-embedding-004'\n\n# --- Helper function for Markdown display ---\ndef to_markdown(text):\n  \"\"\"Converts text to Markdown format for better display.\"\"\"\n  text = text.replace('‚Ä¢', '  *')\n  # Indent the text to make it look like a blockquote\n  return Markdown(textwrap.indent(text, '> ', predicate=lambda _: True))\n\nprint(\"\\nLibraries imported and configuration set.\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-11T15:17:19.225553Z","iopub.execute_input":"2025-04-11T15:17:19.225892Z","iopub.status.idle":"2025-04-11T15:17:23.077937Z","shell.execute_reply.started":"2025-04-11T15:17:19.225867Z","shell.execute_reply":"2025-04-11T15:17:23.077123Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### 2.3. Initialize Generative Models\nWe initialize the Gemini models we'll be using: `gemini-pro-vision` for image analysis and `gemini-pro` for text/recipe generation. We also verify that the chosen embedding model is available.","metadata":{}},{"cell_type":"code","source":"# --- Model Initialization ---\nmodels_initialized = False\nif API_KEY_LOADED:\n    try:\n        print(\"\\nInitializing Generative Models...\")\n        # Model for understanding images\n        vision_model = genai.GenerativeModel('gemini-2.0-flash')\n        # Model for generating text (recipes)\n        text_model = genai.GenerativeModel('gemini-2.0-flash')\n\n        # Check if the embedding model exists before attempting to use it\n        print(f\"Checking availability of embedding model: {EMBEDDING_MODEL_NAME}...\")\n        available_models = [m.name for m in genai.list_models() if 'embedContent' in m.supported_generation_methods]\n        if EMBEDDING_MODEL_NAME not in available_models:\n            print(f\"‚ö†Ô∏è Warning: Embedding model '{EMBEDDING_MODEL_NAME}' not found or doesn't support 'embedContent'.\")\n            # Attempt fallback or list available embedding models\n            available_embedding_models = [m.name for m in available_models if 'embedding' in m.name.lower()]\n            if available_embedding_models:\n                EMBEDDING_MODEL_NAME = available_embedding_models[0] # Use the first available one\n                print(f\"‚û°Ô∏è Switched to available embedding model: {EMBEDDING_MODEL_NAME}\")\n            else:\n                raise ValueError(\"‚ùå Critical: No suitable embedding models found.\")\n        else:\n             print(f\"‚úÖ Embedding model '{EMBEDDING_MODEL_NAME}' is available.\")\n\n        print(\"‚úÖ Models initialized successfully.\")\n        models_initialized = True\n    except Exception as e:\n        print(f\"‚ùå Error initializing models: {e}\")\n        vision_model = None\n        text_model = None\n        EMBEDDING_MODEL_NAME = None\n        models_initialized = False\nelse:\n    print(\"üö´ Skipping model initialization due to missing API Key.\")\n    vision_model = None\n    text_model = None\n    EMBEDDING_MODEL_NAME = None\n    models_initialized = False","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-11T15:17:23.07895Z","iopub.execute_input":"2025-04-11T15:17:23.079417Z","iopub.status.idle":"2025-04-11T15:17:24.15264Z","shell.execute_reply.started":"2025-04-11T15:17:23.079394Z","shell.execute_reply":"2025-04-11T15:17:24.151542Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## 3. Load and Display Input Image\n\nLet's start by loading the image containing the ingredients. Make sure the `IMAGE_PATH` variable points to your image file within the Kaggle input directory.","metadata":{}},{"cell_type":"code","source":"def load_and_display_image(image_path):\n    \"\"\"Loads an image from path and displays it.\"\"\"\n    try:\n        print(f\"\\n--- Loading Image ---\")\n        print(f\"Attempting to load: {image_path}\")\n        # Use IPython.display.Image for reliable display in Kaggle\n        display(IPImage(filename=image_path, width=400))\n        # Also load with PIL for processing\n        img_pil = Image.open(image_path)\n        print(f\"‚úÖ Image loaded successfully.\")\n        return img_pil\n    except FileNotFoundError:\n        print(f\"‚ùå Error: Image file not found at {image_path}\")\n        print(\"‚û°Ô∏è Please ensure the IMAGE_PATH variable is correct and the dataset is attached.\")\n        return None\n    except Exception as e:\n        print(f\"‚ùå Error loading image: {e}\")\n        return None\n\n# --- Execute Image Loading ---\nif models_initialized: # Only proceed if setup was successful\n    input_image_pil = load_and_display_image(IMAGE_PATH)\nelse:\n    print(\"üö´ Cannot load image as models were not initialized.\")\n    input_image_pil = None","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-11T15:17:24.153601Z","iopub.execute_input":"2025-04-11T15:17:24.153946Z","iopub.status.idle":"2025-04-11T15:17:24.218787Z","shell.execute_reply.started":"2025-04-11T15:17:24.153914Z","shell.execute_reply":"2025-04-11T15:17:24.217924Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## 4. Identify Ingredients (Capability 1: Image Understanding)\n\nNow, we use the `gemini-pro-vision` model to analyze the loaded image and identify the food ingredients. This is our first Gen AI capability in action.","metadata":{}},{"cell_type":"code","source":"def identify_ingredients_from_image(image_pil, prompt=\"Identify the main food ingredients visible in this image. List them concisely, separated by commas. Ignore non-food items.\"):\n    \"\"\"Identifies ingredients from a PIL image object using Gemini Vision.\"\"\"\n    if not vision_model:\n        print(\"üö´ Vision model not initialized.\")\n        return None\n    if not image_pil:\n        print(\"üö´ No image provided.\")\n        return None\n\n    print(\"\\n--- Identifying Ingredients (Capability: Image Understanding) ---\")\n    try:\n        # Pass the PIL Image object directly to the model\n        response = vision_model.generate_content([prompt, image_pil])\n\n        # Robustly extract text, handling potential blocks or parts\n        ingredients_text = \"\"\n        if response and hasattr(response, 'text'):\n             ingredients_text = response.text\n        elif response and hasattr(response, 'parts'):\n             text_parts = [part.text for part in response.parts if hasattr(part, 'text')]\n             ingredients_text = \"\\n\".join(text_parts)\n        else:\n            # Attempt to access candidates if direct text access fails\n            try:\n                ingredients_text = response.candidates[0].content.parts[0].text\n            except (AttributeError, IndexError, Exception) as e_inner:\n                 print(f\"‚ö†Ô∏è Vision Model Response might be empty or in unexpected format. Error accessing parts: {e_inner}\")\n                 print(f\"Raw Response: {response}\")\n                 return None\n\n        # Clean up potential markdown list formatting and split\n        print(f\"Raw ingredients text from model: '{ingredients_text}'\")\n        ingredients_text_cleaned = ingredients_text.strip().replace(\"* \", \"\").replace(\"- \", \"\")\n        ingredients_list = [item.strip().lower() for item in ingredients_text_cleaned.split(',') if item.strip()]\n\n        if ingredients_list:\n            print(f\"‚úÖ Identified Ingredients: {', '.join(ingredients_list)}\")\n            return ingredients_list\n        else:\n            print(f\"‚ö†Ô∏è No ingredients identified or extracted from response text: '{ingredients_text_cleaned}'\")\n            return None\n\n    except Exception as e:\n        print(f\"‚ùå Error during ingredient identification: {e}\")\n        # print(f\"Raw Response causing error: {response}\") # Uncomment for debugging\n        return None\n\n# --- Execute Ingredient Identification ---\nidentified_ingredients = None\nif input_image_pil and models_initialized:\n    identified_ingredients = identify_ingredients_from_image(input_image_pil)\nelif not models_initialized:\n     print(\"üö´ Cannot identify ingredients as models were not initialized.\")\nelse:\n     print(\"üö´ Cannot identify ingredients as image was not loaded.\")\n\n# Display identified ingredients clearly\nif identified_ingredients:\n    display(Markdown(f\"**Identified Ingredients:** `{', '.join(identified_ingredients)}`\"))\nelse:\n    display(Markdown(\"**No ingredients were identified.**\"))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-11T15:17:24.221242Z","iopub.execute_input":"2025-04-11T15:17:24.221487Z","iopub.status.idle":"2025-04-11T15:17:25.938555Z","shell.execute_reply.started":"2025-04-11T15:17:24.221468Z","shell.execute_reply":"2025-04-11T15:17:25.937724Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## 5. Prepare RAG Data (Capability 2a: Embeddings)\n\nTo provide relevant context for recipe generation, we implement Retrieval Augmented Generation (RAG). The first part of RAG is preparing our knowledge base (a dataset of recipes) and generating embeddings for it.\n\n### 5.1. Load Recipe Dataset\nWe load a CSV file containing existing recipes. The CSV should have columns like `title`, `ingredients_list`, and `instructions`. We'll create a combined text field from these to generate meaningful embeddings.","metadata":{}},{"cell_type":"markdown","source":"### 5.2. Generate Embeddings for Recipes\nNow we use the embedding model (`models/embedding-001` or similar) to convert the text description of each recipe into a numerical vector (embedding). These embeddings capture the semantic meaning of the recipes.\n\n**Note:** For large datasets, generating embeddings can take time. It's often beneficial to generate them once and save them for later use.","metadata":{}},{"cell_type":"code","source":"def load_recipe_data(csv_path):\n    \"\"\"Loads recipe data, validates, and prepares for embedding.\"\"\"\n    try:\n        print(f\"\\n--- Loading Recipe Data ---\")\n        print(f\"Attempting to load: {csv_path}\")\n        df = pd.read_csv(csv_path)\n        required_cols = ['name_of_recipe', 'ingredients_list', 'how_to_prepare', 'category'] # Adjust if your columns differ\n        if not all(col in df.columns for col in required_cols):\n            raise ValueError(f\"‚ùå CSV must contain columns: {required_cols}\")\n\n        # Simple preprocessing: Create a text field for embedding\n        # Combine relevant fields for better semantic meaning\n        # Ensure ingredients_list is treated as string before concatenation\n        df['ingredients_str'] = df['ingredients_list'].astype(str) # Ensure final string type\n        df['name_of_recipe_str'] = df['name_of_recipe'].astype(str) \n        df['category_str'] = df['category'].astype(str)\n        df['how_to_prepare_str'] = df['how_to_prepare'].astype(str)\n        df['embedding_text'] = df['name_of_recipe'].astype(str) + \": \" + df['ingredients_list'].astype(str) + \": \" + df['how_to_prepare'].astype(str) + \": \" + df['category'].astype(str)\n\n        # Handle potential NaN values introduced or existing\n        df.dropna(subset=['name_of_recipe', 'ingredients_list', 'how_to_prepare', 'category'], inplace=True)\n        df.reset_index(drop=True, inplace=True) # Reset index after dropping rows\n\n        print(f\"‚úÖ Recipe data loaded. Shape: {df.shape}\")\n        if df.empty:\n             print(\"‚ö†Ô∏è Warning: Recipe dataframe is empty after loading/cleaning.\")\n        # Display first few rows\n        display(df.head())\n        return df\n    except FileNotFoundError:\n        print(f\"‚ùå Error: Recipe CSV file not found at {csv_path}\")\n        print(\"‚û°Ô∏è Please ensure the RECIPE_CSV_PATH variable is correct and the dataset is attached.\")\n        return None\n    except Exception as e:\n        print(f\"‚ùå Error loading recipe data: {e}\")\n        return None\n\n# --- Execute Recipe Data Loading ---\nrecipe_df = None\nif models_initialized: # Only load if models are ready for embedding\n    recipe_df = load_recipe_data(RECIPE_CSV_PATH)\nelse:\n    print(\"üö´ Skipping recipe data loading as models are not initialized.\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-11T15:17:25.939416Z","iopub.execute_input":"2025-04-11T15:17:25.939697Z","iopub.status.idle":"2025-04-11T15:17:25.993538Z","shell.execute_reply.started":"2025-04-11T15:17:25.939669Z","shell.execute_reply":"2025-04-11T15:17:25.992749Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def get_embeddings_safe(texts, task_type=\"RETRIEVAL_DOCUMENT\", batch_size=100):\n    \"\"\"Generates embeddings with error handling and batching.\"\"\"\n    if not EMBEDDING_MODEL_NAME or not models_initialized:\n        print(\"üö´ Embedding model not available or not initialized.\")\n        return None\n    if not texts:\n        print(\"üö´ No texts provided for embedding.\")\n        return []\n\n    all_embeddings = []\n    print(f\"\\n--- Generating Embeddings (Capability: Embeddings) ---\")\n    print(f\"Model: {EMBEDDING_MODEL_NAME}, Task Type: {task_type}, Total Texts: {len(texts)}\")\n\n    try:\n        for i in range(0, len(texts), batch_size):\n            batch = texts[i:i+batch_size]\n            print(f\"Processing batch {i//batch_size + 1} ({len(batch)} texts)...\")\n            # Use embed_content for batching\n            result = genai.embed_content(model=EMBEDDING_MODEL_NAME,\n                                          content=batch,\n                                          task_type=task_type)\n            batch_embeddings = result.get('embedding')\n\n            if batch_embeddings:\n                 all_embeddings.extend(batch_embeddings)\n            else:\n                 print(f\"‚ö†Ô∏è Embedding result was empty for batch starting at index {i}. Response: {result}\")\n                 # Handle error - maybe return None or raise exception depending on desired robustness\n                 # For this POC, we'll continue but note the issue. Some embeddings might be missing.\n\n        if len(all_embeddings) == len(texts):\n             print(f\"‚úÖ Successfully generated {len(all_embeddings)} embeddings.\")\n             return all_embeddings\n        else:\n             print(f\"‚ö†Ô∏è Warning: Number of generated embeddings ({len(all_embeddings)}) does not match input texts ({len(texts)}). Some might be missing.\")\n             return all_embeddings # Return partial results\n\n    except Exception as e:\n        print(f\"‚ùå Error generating embeddings: {e}\")\n        # Consider logging the text batch that caused the error if possible\n        return None\n\n# --- Execute Embedding Generation for Recipes ---\nrecipe_embeddings_list = None\nif recipe_df is not None and not recipe_df.empty and models_initialized:\n    # --- DEBUGGING LINE ADDED ---\n    print(\"Columns in recipe_df before accessing 'embedding_text':\", recipe_df.columns)\n    # --- END DEBUGGING LINE ---\n    try: # Added try-except around the access for better error isolation\n        recipe_texts_for_embedding = recipe_df['embedding_text'].tolist()\n        # Use RETRIEVAL_DOCUMENT for the corpus we are searching over\n        recipe_embeddings_list = get_embeddings_safe(recipe_texts_for_embedding, task_type=\"RETRIEVAL_DOCUMENT\")\n    except KeyError as ke:\n        print(f\"‚ùå KeyError confirmed: Column '{ke}' not found in DataFrame.\")\n        print(\"‚û°Ô∏è Please check the output of the load_recipe_data function cell to ensure the column was created.\")\n    except Exception as e_inner:\n         print(f\"‚ùå An unexpected error occurred when accessing 'embedding_text' or calling get_embeddings_safe: {e_inner}\")\nelse:\n    print(\"üö´ Skipping recipe embedding generation (no data or models not initialized).\")\n\n# Convert to NumPy array for efficient calculations later\nrecipe_embeddings_np = None\nif recipe_embeddings_list:\n    try:\n        recipe_embeddings_np = np.array(recipe_embeddings_list)\n        print(f\"‚úÖ Recipe embeddings converted to NumPy array. Shape: {recipe_embeddings_np.shape}\")\n    except Exception as e:\n        print(f\"‚ùå Error converting recipe embeddings to NumPy array: {e}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-11T15:17:25.994578Z","iopub.execute_input":"2025-04-11T15:17:25.994898Z","iopub.status.idle":"2025-04-11T15:17:27.768301Z","shell.execute_reply.started":"2025-04-11T15:17:25.994871Z","shell.execute_reply":"2025-04-11T15:17:27.767441Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## 6. Perform RAG Search (Capability 2b: Vector Search)\n\nWith the recipe embeddings ready, we can now perform the retrieval part of RAG. We'll embed the user's identified ingredients (the query) and then use Vector Search (specifically, cosine similarity) to find the most similar recipes from our dataset.","metadata":{}},{"cell_type":"code","source":"def find_similar_recipes_rag(query_ingredients_list, recipe_df, recipe_embeddings_np, top_k=3):\n    \"\"\"Performs RAG: Embeds query, finds similar recipes via vector search.\"\"\"\n    if not query_ingredients_list:\n        print(\"üö´ Cannot perform RAG search: No query ingredients provided.\")\n        return None\n    if recipe_df is None or recipe_embeddings_np is None or recipe_df.empty or recipe_embeddings_np.size == 0:\n        print(\"üö´ Cannot perform RAG search: Missing or empty recipe data/embeddings.\")\n        return None\n    if not models_initialized:\n         print(\"üö´ Cannot perform RAG search: Models not initialized.\")\n         return None\n\n    print(\"\\n--- Performing RAG Search (Capability: Vector Search) ---\")\n    # 1. Prepare and Embed the Query\n    query_text = \", \".join(query_ingredients_list) # Combine ingredients into a single string\n    print(f\"Embedding query: '{query_text}'\")\n    # Use RETRIEVAL_QUERY for the user query\n    query_embedding = get_embeddings_safe([query_text], task_type=\"RETRIEVAL_QUERY\")\n\n    if not query_embedding:\n        print(\"‚ùå Failed to generate embedding for the query ingredients.\")\n        return None\n\n    # Ensure embedding is a 2D NumPy array for cosine_similarity\n    try:\n        query_embedding_np = np.array(query_embedding[0]).reshape(1, -1)\n    except Exception as e:\n        print(f\"‚ùå Error reshaping query embedding: {e}\")\n        return None\n\n\n    # 2. Calculate Similarities\n    print(\"Calculating similarities...\")\n    try:\n        # Compare query embedding against all recipe embeddings\n        similarities = cosine_similarity(query_embedding_np, recipe_embeddings_np)[0]\n    except Exception as e:\n        print(f\"‚ùå Error calculating cosine similarity: {e}\")\n        print(f\"Query embedding shape: {query_embedding_np.shape}\")\n        print(f\"Recipe embeddings shape: {recipe_embeddings_np.shape}\")\n        return None\n\n\n    # 3. Get Top K Results\n    num_recipes = len(similarities)\n    actual_top_k = min(top_k, num_recipes) # Ensure top_k is not larger than available recipes\n    if actual_top_k <= 0:\n        print(\"‚ö†Ô∏è No recipes found to compare against.\")\n        return None\n\n    # Get indices sorted by similarity (highest first)\n    # Argsort returns indices from lowest to highest, so we reverse it [::-1]\n    top_indices = np.argsort(similarities)[::-1][:actual_top_k]\n\n    # 4. Retrieve and display results\n    similar_recipes_df = recipe_df.iloc[top_indices].copy() # Use .copy() to avoid SettingWithCopyWarning\n    similar_recipes_df['similarity'] = similarities[top_indices] # Add similarity score\n\n    print(f\"‚úÖ Found Top {len(similar_recipes_df)} Relevant Recipes (Context for Generator):\")\n    # Display the context that will be fed to the generator\n    for index, row in similar_recipes_df.iterrows():\n        display(Markdown(f\"- **{row['name_of_recipe']}** (Similarity: {row['similarity']:.4f})\"))\n        # Optionally display ingredients for context inspection\n        # display(Markdown(f\"  *Ingredients:* {row['ingredients_str'][:100]}...\"))\n\n    return similar_recipes_df\n\n\n# --- Execute RAG Search ---\nrag_context_recipes = None\nif identified_ingredients and recipe_df is not None and recipe_embeddings_np is not None and models_initialized:\n    rag_context_recipes = find_similar_recipes_rag(identified_ingredients, recipe_df, recipe_embeddings_np, top_k=3)\nelif not models_initialized:\n    print(\"üö´ Cannot perform RAG search as models are not initialized.\")\nelif not identified_ingredients:\n    print(\"üö´ Cannot perform RAG search as no ingredients were identified.\")\nelse:\n    print(\"üö´ Cannot perform RAG search due to missing recipe data or embeddings.\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-11T15:17:27.769169Z","iopub.execute_input":"2025-04-11T15:17:27.769526Z","iopub.status.idle":"2025-04-11T15:17:28.1082Z","shell.execute_reply.started":"2025-04-11T15:17:27.769477Z","shell.execute_reply":"2025-04-11T15:17:28.107377Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## 7. Generate Recipe (Capability 3: Structured Output - JSON)\n\nWe have the identified ingredients and relevant context from RAG. Now, we use the `gemini-pro` model to generate the final recipe. We explicitly instruct the model to provide the output in a structured JSON format. This makes the output predictable and easy to parse.","metadata":{}},{"cell_type":"code","source":"def generate_recipe_structured(ingredients_list, context_recipes_df=None):\n    \"\"\"Generates a recipe using Gemini Pro, requesting structured JSON output.\"\"\"\n    if not text_model:\n        print(\"üö´ Text model not initialized.\")\n        return None\n    if not ingredients_list:\n        print(\"üö´ No ingredients provided for recipe generation.\")\n        return None\n\n    print(\"\\n--- Generating Recipe (Capability: Structured Output - JSON) ---\")\n\n    ingredients_str = \", \".join(ingredients_list)\n    # --- Crafting the Prompt ---\n    prompt_parts = [f\"You are an expert and creative chef. Your task is to create a unique and delicious recipe primarily using ONLY these ingredients: **{ingredients_str}**.\"]\n    prompt_parts.append(\"Assume basic pantry staples like salt, pepper, oil, and water are available unless contradicted by the provided ingredients.\")\n\n    # Add context from RAG if available\n    if context_recipes_df is not None and not context_recipes_df.empty:\n        prompt_parts.append(\"\\nFor inspiration, consider these related recipe titles (but ensure your generated recipe is unique and uses the main ingredients provided):\")\n        for _, row in context_recipes_df.head(3).iterrows(): # Limit context length\n            prompt_parts.append(f\"- {row['name_of_recipe']}\")\n\n    # Explicit JSON structure instruction - VERY IMPORTANT\n    prompt_parts.append(\"\\n**CRITICAL INSTRUCTION:** Your response MUST be a single, valid JSON object ONLY. Do NOT include any text, explanation, apologies, or markdown formatting (like ```json) before or after the JSON object. The JSON object must strictly adhere to the following structure with these exact keys:\")\n    prompt_parts.append(\"\"\"\n{\n  \"title\": \"A creative and fitting name for the dish (string)\",\n  \"description\": \"A brief, appealing description of the final dish (string, 1-2 sentences)\",\n  \"ingredients_required\": [\n    \"List of required ingredients with precise quantities (list of strings, e.g., '1 cup flour', '2 tbsp olive oil', 'Salt to taste')\"\n  ],\n  \"instructions\": [\n    \"Step-by-step cooking instructions (list of strings, each step clearly explained)\"\n  ],\n  \"prep_time_minutes\": \"Estimated preparation time in minutes (integer)\",\n  \"cook_time_minutes\": \"Estimated cooking time in minutes (integer)\",\n  \"servings\": \"Estimated number of servings (integer)\"\n}\n\"\"\")\n    prompt_parts.append(\"Ensure all string values are properly quoted and the overall structure is valid JSON.\")\n\n    full_prompt = \"\\n\".join(prompt_parts)\n    # --- Uncomment the next lines to debug the exact prompt being sent ---\n    # print(\"\\n--- Prompt for Recipe Generation ---\")\n    # print(full_prompt)\n    # print(\"--- End Prompt ---\")\n\n    try:\n        # Configure generation parameters (optional)\n        generation_config = genai.types.GenerationConfig(\n             # response_mime_type=\"application/json\", # Enable this if/when the API fully supports reliable JSON mode enforcement\n             temperature=0.75, # Adjust for creativity vs. predictability\n             # max_output_tokens=1024 # Set limits if needed\n        )\n\n        print(\"Sending request to generate recipe...\")\n        response = text_model.generate_content(\n            full_prompt,\n            generation_config=generation_config,\n            # safety_settings=... # Add safety settings if needed\n        )\n\n        # --- Robust JSON Parsing ---\n        print(\"Parsing response...\")\n        raw_text = response.text.strip()\n        # print(f\"\\nRaw Model Response Text:\\n{raw_text}\") # Uncomment for debugging\n\n        # Attempt to find the JSON block, removing potential markdown fences or introductory text\n        json_str = raw_text\n        if '```json' in json_str:\n            json_str = json_str.split('```json')[1].split('```')[0].strip()\n        elif json_str.startswith('{') and json_str.endswith('}'):\n             pass # Looks like JSON already\n        else:\n             # Fallback: Try to find the first '{' and last '}' - might be fragile\n             start = json_str.find('{')\n             end = json_str.rfind('}')\n             if start != -1 and end != -1 and start < end:\n                  json_str = json_str[start:end+1]\n                  print(\"‚ö†Ô∏è Warning: Extracted JSON using fallback method (finding first '{' and last '}'). May be incomplete.\")\n             else:\n                  print(f\"‚ùå Error: Could not reliably extract JSON block from response. Raw text:\\n{raw_text}\")\n                  return None\n\n        try:\n            # Attempt to load the extracted string as JSON\n            recipe_json = json.loads(json_str)\n\n            # Validate required keys are present in the parsed JSON\n            required_keys = ['title', 'description', 'ingredients_required', 'instructions', 'prep_time_minutes', 'cook_time_minutes', 'servings']\n            missing_keys = [k for k in required_keys if k not in recipe_json]\n            if not missing_keys:\n                 print(\"‚úÖ Successfully generated and parsed recipe JSON.\")\n                 return recipe_json\n            else:\n                 print(f\"‚ùå Error: Generated JSON is missing required keys: {missing_keys}\")\n                 print(f\"Problematic JSON parsed: {recipe_json}\")\n                 return None\n        except json.JSONDecodeError as json_err:\n             print(f\"‚ùå Error: Could not decode JSON from extracted text: {json_err}\")\n             print(f\"Problematic Text Block attempted to parse:\\n{json_str}\")\n             return None\n\n    except Exception as e:\n        print(f\"‚ùå Error during recipe generation API call: {e}\")\n        # print(f\"Response object at time of error: {response}\") # Uncomment for debugging\n        return None\n\n# --- Execute Recipe Generation ---\ngenerated_recipe_json = None\nif identified_ingredients and models_initialized:\n    generated_recipe_json = generate_recipe_structured(identified_ingredients, rag_context_recipes)\nelif not models_initialized:\n    print(\"üö´ Cannot generate recipe as models are not initialized.\")\nelse:\n    print(\"üö´ Cannot generate recipe as no ingredients were identified.\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-11T15:17:28.109169Z","iopub.execute_input":"2025-04-11T15:17:28.109926Z","iopub.status.idle":"2025-04-11T15:17:31.449916Z","shell.execute_reply.started":"2025-04-11T15:17:28.109902Z","shell.execute_reply":"2025-04-11T15:17:31.449059Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## 8. Display Final Recipe\n\nFinally, we parse the generated JSON and display the recipe in a user-friendly format using Markdown.","metadata":{}},{"cell_type":"code","source":"def display_recipe(recipe_json):\n    \"\"\"Displays the generated recipe JSON in a nice Markdown format.\"\"\"\n    if not recipe_json:\n        display(Markdown(\"### <center>‚ùå Recipe Generation Failed ‚ùå</center>\"))\n        return\n\n    print(\"\\n\\n\" + \"=\"*25 + \" üçΩÔ∏è FINAL GENERATED RECIPE üçΩÔ∏è \" + \"=\"*25)\n    try:\n        # --- Title ---\n        display(Markdown(f\"# {recipe_json.get('title', 'Untitled Recipe')}\"))\n\n        # --- Description ---\n        display(Markdown(f\"*{recipe_json.get('description', 'No description provided.')}*\"))\n\n        # --- Time & Servings ---\n        prep_time = recipe_json.get('prep_time_minutes', '?')\n        cook_time = recipe_json.get('cook_time_minutes', '?')\n        servings = recipe_json.get('servings', '?')\n        display(Markdown(f\"**Prep time:** {prep_time} min | **Cook time:** {cook_time} min | **Servings:** {servings}\"))\n\n        # --- Ingredients ---\n        display(Markdown(\"## Ingredients\"))\n        ingredients = recipe_json.get('ingredients_required', [])\n        if ingredients and isinstance(ingredients, list):\n            ingredients_md = \"\\n\".join([f\"- {item}\" for item in ingredients])\n            display(Markdown(ingredients_md))\n        else:\n            display(Markdown(\"- N/A\"))\n\n        # --- Instructions ---\n        display(Markdown(\"## Instructions\"))\n        instructions = recipe_json.get('instructions', [])\n        if instructions and isinstance(instructions, list):\n            instructions_md = \"\\n\".join([f\"{i+1}. {step}\" for i, step in enumerate(instructions)])\n            display(Markdown(instructions_md))\n        else:\n            display(Markdown(\"1. N/A\"))\n\n        print(\"=\"*70)\n\n    except Exception as e:\n        print(f\"‚ùå Error formatting recipe display: {e}\")\n        print(\"Raw JSON data:\")\n        print(recipe_json) # Print the raw JSON if formatting fails\n\n# --- Display the result ---\nif generated_recipe_json:\n    display_recipe(generated_recipe_json)\nelse:\n    # Display failure message if JSON is None\n    display_recipe(None)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-11T15:17:31.451041Z","iopub.execute_input":"2025-04-11T15:17:31.451331Z","iopub.status.idle":"2025-04-11T15:17:31.470762Z","shell.execute_reply.started":"2025-04-11T15:17:31.451309Z","shell.execute_reply":"2025-04-11T15:17:31.469993Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## 9. Conclusion\n\n### 9.1. Summary\nThis notebook successfully demonstrated an AI-powered Recipe Generator. By leveraging Google's Generative AI models, along with embedding techniques, we achieved the following:\n1.  **Identified** ingredients from an input image (**Image Understanding**).\n2.  **Retrieved** relevant recipe context from a knowledge base using **Embeddings** and **Vector Search** (**RAG**).\n3.  **Generated** a novel, structured recipe in JSON format (**Structured Output**).\n\nThis project showcases how multiple Gen AI capabilities can be combined to create a practical and helpful application, fulfilling the core requirements of the Capstone challenge.\n\n### 9.2. Limitations & Challenges\n* **Ingredient Identification Accuracy:** accuracy can vary depending on image quality, lighting, ingredient obscurity, and how items are arranged. It might miss items or misidentify similar ones.\n* **RAG Context Relevance:** The quality of the RAG context depends heavily on the underlying recipe dataset and the effectiveness of the embeddings. A small or poorly chosen dataset will limit the inspiration for the generator. The chosen embedding model also impacts semantic understanding.\n* **Recipe Quality & Creativity:** The generated recipe's quality, coherence, and safety depend on the model's capabilities and the prompt's clarity. While instructed to use *only* provided ingredients, it might occasionally hallucinate minor additions. Generated recipes should always be reviewed for sensibility before attempting.\n* **Structured Output Enforcement:** While we strongly prompted for JSON, LLMs can sometimes fail to adhere perfectly, requiring robust parsing logic or future API improvements for guaranteed JSON mode.\n* **Dataset Size & Scope:** The POC uses a small recipe dataset. A real-world application would need a much larger, diverse, and well-curated dataset for effective RAG.\n\n### 9.3. Future Work & Potential Improvements\n* **Larger & Better Dataset:** Incorporate a comprehensive recipe dataset (e.g., RecipeNLG, ensuring license compliance) for richer RAG context.\n* **Advanced Vector Database:** Replace the simple NumPy/cosine similarity search with a dedicated vector database (like ChromaDB, FAISS, or Vertex AI Vector Search) for scalability and more efficient searching.\n* **User Interaction:** Allow users to confirm/edit the identified ingredients list before proceeding.\n* **Dietary Preferences & Filters:** Enable users to specify dietary restrictions (vegetarian, gluten-free) or cuisine preferences to guide recipe generation.\n* **Multi-Image Input:** Allow users to upload multiple images (e.g., fridge and pantry) for a more complete ingredient list.\n* **Fine-tuning (Optional):** For highly specialized recipe generatio.","metadata":{}}]}